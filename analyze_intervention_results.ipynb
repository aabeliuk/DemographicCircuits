{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervention Results Analysis\n",
    "\n",
    "This notebook analyzes the results of demographic circuit interventions on the ANES 2024 dataset.\n",
    "\n",
    "**Analyses included:**\n",
    "- Summary statistics for single-demographic and intersectional interventions\n",
    "- Comparison visualizations (baseline vs intervention)\n",
    "- Per-question analysis\n",
    "- Per-demographic analysis (which demographics improve accuracy most)\n",
    "- Advanced metrics (Kendall's tau, entropy, F1, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Modify these parameters\n",
    "# ============================================================================\n",
    "\n",
    "RUN_ID = \"exp_001\"  # Change this to your run ID\n",
    "PROBE_TYPE = \"ridge\"  # ridge or logistic\n",
    "RESULTS_DIR = Path(\"robust_experiment_results/intervention_results\")\n",
    "\n",
    "# Demographics to analyze\n",
    "SINGLE_DEMOGRAPHICS = ['age', 'gender', 'ideology', 'race']\n",
    "INTERSECTIONAL_DEMOGRAPHICS = ['age+gender+ideology+race']  # Add more if you have them\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Run ID: {RUN_ID}\")\n",
    "print(f\"  Probe Type: {PROBE_TYPE}\")\n",
    "print(f\"  Results Directory: {RESULTS_DIR}\")\n",
    "print(f\"  Single Demographics: {SINGLE_DEMOGRAPHICS}\")\n",
    "print(f\"  Intersectional: {INTERSECTIONAL_DEMOGRAPHICS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summary JSON\n",
    "summary_file = RESULTS_DIR / f\"intervention_summary_{RUN_ID}.json\"\n",
    "\n",
    "if summary_file.exists():\n",
    "    with open(summary_file, 'r') as f:\n",
    "        summary_data = json.load(f)\n",
    "    print(f\"âœ“ Loaded summary from: {summary_file}\")\n",
    "    print(f\"  Mode: {summary_data.get('mode', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"âœ— Summary file not found: {summary_file}\")\n",
    "    summary_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load single-demographic results\n",
    "single_demo_results = {}\n",
    "\n",
    "for demographic in SINGLE_DEMOGRAPHICS:\n",
    "    result_file = RESULTS_DIR / f\"{demographic}_{PROBE_TYPE}_{RUN_ID}_intervention_results.pkl\"\n",
    "    \n",
    "    if result_file.exists():\n",
    "        with open(result_file, 'rb') as f:\n",
    "            single_demo_results[demographic] = pickle.load(f)\n",
    "        print(f\"âœ“ Loaded {demographic}: {result_file.name}\")\n",
    "    else:\n",
    "        print(f\"âœ— Not found: {demographic}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(single_demo_results)} single-demographic results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load intersectional results\n",
    "intersectional_results = {}\n",
    "\n",
    "for demographics in INTERSECTIONAL_DEMOGRAPHICS:\n",
    "    result_file = RESULTS_DIR / f\"intersectional_{demographics}_{PROBE_TYPE}_{RUN_ID}_intervention_results.pkl\"\n",
    "    \n",
    "    if result_file.exists():\n",
    "        with open(result_file, 'rb') as f:\n",
    "            intersectional_results[demographics] = pickle.load(f)\n",
    "        print(f\"âœ“ Loaded intersectional {demographics}: {result_file.name}\")\n",
    "    else:\n",
    "        print(f\"âœ— Not found: intersectional {demographics}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(intersectional_results)} intersectional results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary Statistics Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Overall Metrics: Single Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract overall metrics for single demographics\n",
    "summary_rows = []\n",
    "\n",
    "for demo, results in single_demo_results.items():\n",
    "    metrics = results['overall_metrics']\n",
    "    \n",
    "    row = {\n",
    "        'Demographic': demo.capitalize(),\n",
    "        'Baseline Acc': f\"{metrics['baseline_accuracy_mean']*100:.1f}%\",\n",
    "        'Baseline Std': f\"{metrics['baseline_accuracy_std']*100:.1f}%\" if metrics['baseline_accuracy_std'] else 'N/A',\n",
    "        'Intervention Acc': f\"{metrics['intervention_accuracy_mean']*100:.1f}%\",\n",
    "        'Intervention Std': f\"{metrics['intervention_accuracy_std']*100:.1f}%\" if metrics['intervention_accuracy_std'] else 'N/A',\n",
    "        'Improvement': f\"{metrics['improvement_mean']:+.1f}\",\n",
    "        'Improvement Std': f\"{metrics['improvement_std']:.1f}\" if metrics['improvement_std'] else 'N/A',\n",
    "    }\n",
    "    summary_rows.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SINGLE-DEMOGRAPHIC INTERVENTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Overall Metrics: Intersectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract overall metrics for intersectional\n",
    "intersect_rows = []\n",
    "\n",
    "for demographics, results in intersectional_results.items():\n",
    "    metrics = results['overall_metrics']\n",
    "    \n",
    "    row = {\n",
    "        'Demographics': demographics,\n",
    "        'Baseline Acc': f\"{metrics['baseline_accuracy_mean']*100:.1f}%\",\n",
    "        'Baseline Std': f\"{metrics['baseline_accuracy_std']*100:.1f}%\" if metrics['baseline_accuracy_std'] else 'N/A',\n",
    "        'Intervention Acc': f\"{metrics['intervention_accuracy_mean']*100:.1f}%\",\n",
    "        'Intervention Std': f\"{metrics['intervention_accuracy_std']*100:.1f}%\" if metrics['intervention_accuracy_std'] else 'N/A',\n",
    "        'Improvement': f\"{metrics['improvement_mean']:+.1f}\",\n",
    "        'Improvement Std': f\"{metrics['improvement_std']:.1f}\" if metrics['improvement_std'] else 'N/A',\n",
    "    }\n",
    "    intersect_rows.append(row)\n",
    "\n",
    "if intersect_rows:\n",
    "    intersect_df = pd.DataFrame(intersect_rows)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INTERSECTIONAL INTERVENTION SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    display(intersect_df)\n",
    "else:\n",
    "    print(\"No intersectional results found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Advanced Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced metrics for single demographics\n",
    "advanced_rows = []\n",
    "\n",
    "for demo, results in single_demo_results.items():\n",
    "    metrics = results['overall_metrics']\n",
    "    \n",
    "    # Helper function to format metric with std\n",
    "    def fmt(mean_key, std_key):\n",
    "        mean_val = metrics.get(mean_key)\n",
    "        std_val = metrics.get(std_key)\n",
    "        if mean_val is None:\n",
    "            return 'N/A'\n",
    "        if std_val is None or std_val == 0:\n",
    "            return f\"{mean_val:.3f}\"\n",
    "        return f\"{mean_val:.3f} Â± {std_val:.3f}\"\n",
    "    \n",
    "    row = {\n",
    "        'Demographic': demo.capitalize(),\n",
    "        \"Kendall's Ï„ (Baseline)\": fmt('baseline_kendall_tau_mean', 'baseline_kendall_tau_std'),\n",
    "        \"Kendall's Ï„ (Intervention)\": fmt('intervention_kendall_tau_mean', 'intervention_kendall_tau_std'),\n",
    "        'Entropy (Baseline)': fmt('baseline_entropy_mean', 'baseline_entropy_std'),\n",
    "        'JS Divergence (Baseline)': fmt('baseline_js_divergence_mean', 'baseline_js_divergence_std'),\n",
    "        'Macro F1 (Intervention)': fmt('intervention_macro_f1_mean', 'intervention_macro_f1_std'),\n",
    "        \"Cohen's Îº (Intervention)\": fmt('intervention_cohen_kappa_mean', 'intervention_cohen_kappa_std'),\n",
    "    }\n",
    "    advanced_rows.append(row)\n",
    "\n",
    "advanced_df = pd.DataFrame(advanced_rows)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADVANCED METRICS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "display(advanced_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparison Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Baseline vs Intervention Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for visualization\n",
    "demographics = []\n",
    "baseline_accs = []\n",
    "intervention_accs = []\n",
    "\n",
    "for demo, results in single_demo_results.items():\n",
    "    metrics = results['overall_metrics']\n",
    "    demographics.append(demo.capitalize())\n",
    "    baseline_accs.append(metrics['baseline_accuracy_mean'] * 100)\n",
    "    intervention_accs.append(metrics['intervention_accuracy_mean'] * 100)\n",
    "\n",
    "# Create grouped bar chart\n",
    "x = np.arange(len(demographics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, baseline_accs, width, label='Baseline', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, intervention_accs, width, label='Intervention', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Demographic Attribute')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Baseline vs Intervention Accuracy by Demographic')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(demographics)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Accuracy Improvement by Demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare improvement data\n",
    "demographics = []\n",
    "improvements = []\n",
    "improvement_stds = []\n",
    "\n",
    "for demo, results in single_demo_results.items():\n",
    "    metrics = results['overall_metrics']\n",
    "    demographics.append(demo.capitalize())\n",
    "    improvements.append(metrics['improvement_mean'])\n",
    "    improvement_stds.append(metrics['improvement_std'] if metrics['improvement_std'] else 0)\n",
    "\n",
    "# Sort by improvement\n",
    "sorted_indices = np.argsort(improvements)[::-1]\n",
    "demographics = [demographics[i] for i in sorted_indices]\n",
    "improvements = [improvements[i] for i in sorted_indices]\n",
    "improvement_stds = [improvement_stds[i] for i in sorted_indices]\n",
    "\n",
    "# Create bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
    "bars = ax.bar(demographics, improvements, yerr=improvement_stds, \n",
    "              color=colors, alpha=0.7, capsize=5)\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax.set_xlabel('Demographic Attribute')\n",
    "ax.set_ylabel('Accuracy Improvement (percentage points)')\n",
    "ax.set_title('Accuracy Improvement by Demographic (Intervention - Baseline)')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, imp, std) in enumerate(zip(bars, improvements, improvement_stds)):\n",
    "    height = bar.get_height()\n",
    "    label = f'{imp:+.1f}' if std == 0 else f'{imp:+.1f} Â± {std:.1f}'\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            label,\n",
    "            ha='center', va='bottom' if height > 0 else 'top', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest improvement: {demographics[0]} ({improvements[0]:+.1f} points)\")\n",
    "print(f\"Worst improvement: {demographics[-1]} ({improvements[-1]:+.1f} points)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Kendall's Tau Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Kendall's tau data\n",
    "demographics = []\n",
    "baseline_taus = []\n",
    "intervention_taus = []\n",
    "\n",
    "for demo, results in single_demo_results.items():\n",
    "    metrics = results['overall_metrics']\n",
    "    baseline_tau = metrics.get('baseline_kendall_tau_mean')\n",
    "    intervention_tau = metrics.get('intervention_kendall_tau_mean')\n",
    "    \n",
    "    if baseline_tau is not None and intervention_tau is not None:\n",
    "        demographics.append(demo.capitalize())\n",
    "        baseline_taus.append(baseline_tau)\n",
    "        intervention_taus.append(intervention_tau)\n",
    "\n",
    "if demographics:\n",
    "    x = np.arange(len(demographics))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bars1 = ax.bar(x - width/2, baseline_taus, width, label='Baseline', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, intervention_taus, width, label='Intervention', alpha=0.8)\n",
    "\n",
    "    ax.set_xlabel('Demographic Attribute')\n",
    "    ax.set_ylabel(\"Kendall's Tau\")\n",
    "    ax.set_title(\"Kendall's Tau: Baseline vs Intervention\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(demographics)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No Kendall's tau data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Advanced Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare key advanced metrics\n",
    "metric_pairs = [\n",
    "    ('baseline_entropy_mean', 'intervention_entropy_mean', 'Entropy'),\n",
    "    ('baseline_js_divergence_mean', 'intervention_js_divergence_mean', 'JS Divergence'),\n",
    "    ('baseline_macro_f1_mean', 'intervention_macro_f1_mean', 'Macro F1'),\n",
    "    ('baseline_cohen_kappa_mean', 'intervention_cohen_kappa_mean', \"Cohen's Kappa\")\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (baseline_key, intervention_key, metric_name) in enumerate(metric_pairs):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    demographics = []\n",
    "    baseline_vals = []\n",
    "    intervention_vals = []\n",
    "    \n",
    "    for demo, results in single_demo_results.items():\n",
    "        metrics = results['overall_metrics']\n",
    "        baseline_val = metrics.get(baseline_key)\n",
    "        intervention_val = metrics.get(intervention_key)\n",
    "        \n",
    "        if baseline_val is not None and intervention_val is not None:\n",
    "            demographics.append(demo.capitalize())\n",
    "            baseline_vals.append(baseline_val)\n",
    "            intervention_vals.append(intervention_val)\n",
    "    \n",
    "    if demographics:\n",
    "        x = np.arange(len(demographics))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, baseline_vals, width, label='Baseline', alpha=0.8)\n",
    "        ax.bar(x + width/2, intervention_vals, width, label='Intervention', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Demographic')\n",
    "        ax.set_ylabel(metric_name)\n",
    "        ax.set_title(f'{metric_name}: Baseline vs Intervention')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(demographics, rotation=45, ha='right')\n",
    "        ax.legend()\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f'No {metric_name} data', \n",
    "                ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Per-Question Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Extract Per-Question Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract per-question results from fold_results\n",
    "per_question_data = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for demo, results in single_demo_results.items():\n",
    "    for fold in results['fold_results']:\n",
    "        for question, q_result in fold['test_results'].items():\n",
    "            per_question_data[question][demo] = {\n",
    "                'baseline_accuracy': q_result['baseline_accuracy'],\n",
    "                'intervention_accuracy': q_result['intervention_accuracy'],\n",
    "                'improvement': q_result['improvement'],\n",
    "                'n_samples': q_result['n_samples']\n",
    "            }\n",
    "\n",
    "print(f\"Found {len(per_question_data)} unique questions\")\n",
    "print(f\"\\nSample questions:\")\n",
    "for i, q in enumerate(list(per_question_data.keys())[:5]):\n",
    "    print(f\"  {i+1}. {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Question-Level Improvement Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of improvements: Questions Ã— Demographics\n",
    "questions = list(per_question_data.keys())\n",
    "demographics = list(single_demo_results.keys())\n",
    "\n",
    "# Build improvement matrix\n",
    "improvement_matrix = []\n",
    "for question in questions:\n",
    "    row = []\n",
    "    for demo in demographics:\n",
    "        if demo in per_question_data[question]:\n",
    "            row.append(per_question_data[question][demo]['improvement'])\n",
    "        else:\n",
    "            row.append(np.nan)\n",
    "    improvement_matrix.append(row)\n",
    "\n",
    "improvement_matrix = np.array(improvement_matrix)\n",
    "\n",
    "# Plot heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, max(8, len(questions) * 0.3)))\n",
    "im = ax.imshow(improvement_matrix, cmap='RdYlGn', aspect='auto', vmin=-20, vmax=20)\n",
    "\n",
    "# Set ticks\n",
    "ax.set_xticks(np.arange(len(demographics)))\n",
    "ax.set_yticks(np.arange(len(questions)))\n",
    "ax.set_xticklabels([d.capitalize() for d in demographics])\n",
    "ax.set_yticklabels(questions)\n",
    "\n",
    "# Rotate x labels\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Improvement (percentage points)', rotation=270, labelpad=20)\n",
    "\n",
    "ax.set_title('Accuracy Improvement by Question and Demographic')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Interactive Question Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a question to analyze in detail\n",
    "question_to_analyze = list(per_question_data.keys())[0]  # Change index to explore different questions\n",
    "\n",
    "print(f\"Analyzing question: {question_to_analyze}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Show results for this question across demographics\n",
    "question_results = []\n",
    "for demo in demographics:\n",
    "    if demo in per_question_data[question_to_analyze]:\n",
    "        data = per_question_data[question_to_analyze][demo]\n",
    "        question_results.append({\n",
    "            'Demographic': demo.capitalize(),\n",
    "            'Baseline Acc': f\"{data['baseline_accuracy']*100:.1f}%\",\n",
    "            'Intervention Acc': f\"{data['intervention_accuracy']*100:.1f}%\",\n",
    "            'Improvement': f\"{data['improvement']:+.1f}\",\n",
    "            'Samples': data['n_samples']\n",
    "        })\n",
    "\n",
    "question_df = pd.DataFrame(question_results)\n",
    "display(question_df)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "demo_names = [r['Demographic'] for r in question_results]\n",
    "improvements = [float(r['Improvement']) for r in question_results]\n",
    "\n",
    "colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
    "ax.bar(demo_names, improvements, color=colors, alpha=0.7)\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax.set_xlabel('Demographic')\n",
    "ax.set_ylabel('Improvement (percentage points)')\n",
    "ax.set_title(f'Intervention Improvement for: {question_to_analyze}')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Per-Demographic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Which Demographics Improve Accuracy Most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank demographics by overall improvement\n",
    "demographic_rankings = []\n",
    "\n",
    "for demo, results in single_demo_results.items():\n",
    "    metrics = results['overall_metrics']\n",
    "    demographic_rankings.append({\n",
    "        'Demographic': demo.capitalize(),\n",
    "        'Mean Improvement': metrics['improvement_mean'],\n",
    "        'Std Improvement': metrics['improvement_std'] if metrics['improvement_std'] else 0,\n",
    "        'Baseline Accuracy': metrics['baseline_accuracy_mean'] * 100,\n",
    "        'Intervention Accuracy': metrics['intervention_accuracy_mean'] * 100\n",
    "    })\n",
    "\n",
    "ranking_df = pd.DataFrame(demographic_rankings).sort_values('Mean Improvement', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEMOGRAPHIC RANKINGS (by Accuracy Improvement)\")\n",
    "print(\"=\"*80)\n",
    "display(ranking_df)\n",
    "\n",
    "print(f\"\\nðŸ† Best performing demographic: {ranking_df.iloc[0]['Demographic']} (+{ranking_df.iloc[0]['Mean Improvement']:.2f} points)\")\n",
    "print(f\"   Worst performing demographic: {ranking_df.iloc[-1]['Demographic']} ({ranking_df.iloc[-1]['Mean Improvement']:+.2f} points)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Success Rate: Percentage of Questions with Positive Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate success rate per demographic\n",
    "success_rates = []\n",
    "\n",
    "for demo in demographics:\n",
    "    positive_improvements = 0\n",
    "    total_questions = 0\n",
    "    \n",
    "    for question, demo_results in per_question_data.items():\n",
    "        if demo in demo_results:\n",
    "            total_questions += 1\n",
    "            if demo_results[demo]['improvement'] > 0:\n",
    "                positive_improvements += 1\n",
    "    \n",
    "    if total_questions > 0:\n",
    "        success_rate = (positive_improvements / total_questions) * 100\n",
    "        success_rates.append({\n",
    "            'Demographic': demo.capitalize(),\n",
    "            'Questions with Improvement': positive_improvements,\n",
    "            'Total Questions': total_questions,\n",
    "            'Success Rate': f\"{success_rate:.1f}%\"\n",
    "        })\n",
    "\n",
    "success_df = pd.DataFrame(success_rates)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUCCESS RATE BY DEMOGRAPHIC\")\n",
    "print(\"=\"*80)\n",
    "display(success_df)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "demo_names = [r['Demographic'] for r in success_rates]\n",
    "success_pcts = [float(r['Success Rate'].strip('%')) for r in success_rates]\n",
    "\n",
    "bars = ax.bar(demo_names, success_pcts, alpha=0.7, color='steelblue')\n",
    "ax.axhline(y=50, color='red', linestyle='--', linewidth=1, label='50% threshold')\n",
    "ax.set_xlabel('Demographic')\n",
    "ax.set_ylabel('Success Rate (%)')\n",
    "ax.set_title('Percentage of Questions with Positive Improvement by Demographic')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, pct in zip(bars, success_pcts):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{pct:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Effect Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of improvements for each demographic\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "improvement_distributions = []\n",
    "demo_labels = []\n",
    "\n",
    "for demo in demographics:\n",
    "    improvements = []\n",
    "    for question, demo_results in per_question_data.items():\n",
    "        if demo in demo_results:\n",
    "            improvements.append(demo_results[demo]['improvement'])\n",
    "    \n",
    "    if improvements:\n",
    "        improvement_distributions.append(improvements)\n",
    "        demo_labels.append(demo.capitalize())\n",
    "\n",
    "# Create violin plot\n",
    "parts = ax.violinplot(improvement_distributions, positions=range(len(demo_labels)), \n",
    "                      showmeans=True, showmedians=True)\n",
    "\n",
    "ax.axhline(y=0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax.set_xticks(range(len(demo_labels)))\n",
    "ax.set_xticklabels(demo_labels)\n",
    "ax.set_xlabel('Demographic')\n",
    "ax.set_ylabel('Improvement (percentage points)')\n",
    "ax.set_title('Distribution of Accuracy Improvements Across Questions')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Best demographic\n",
    "best_demo = ranking_df.iloc[0]\n",
    "print(f\"\\n1. BEST PERFORMING DEMOGRAPHIC\")\n",
    "print(f\"   {best_demo['Demographic']}: +{best_demo['Mean Improvement']:.2f} points improvement\")\n",
    "print(f\"   {best_demo['Baseline Accuracy']:.1f}% (baseline) â†’ {best_demo['Intervention Accuracy']:.1f}% (intervention)\")\n",
    "\n",
    "# Success rates\n",
    "if success_rates:\n",
    "    best_success = max(success_rates, key=lambda x: float(x['Success Rate'].strip('%')))\n",
    "    print(f\"\\n2. HIGHEST SUCCESS RATE\")\n",
    "    print(f\"   {best_success['Demographic']}: {best_success['Success Rate']} of questions improved\")\n",
    "    print(f\"   ({best_success['Questions with Improvement']}/{best_success['Total Questions']} questions)\")\n",
    "\n",
    "# Overall statistics\n",
    "all_improvements = []\n",
    "for demo in demographics:\n",
    "    for question, demo_results in per_question_data.items():\n",
    "        if demo in demo_results:\n",
    "            all_improvements.append(demo_results[demo]['improvement'])\n",
    "\n",
    "if all_improvements:\n",
    "    print(f\"\\n3. OVERALL STATISTICS\")\n",
    "    print(f\"   Mean improvement: {np.mean(all_improvements):+.2f} points\")\n",
    "    print(f\"   Median improvement: {np.median(all_improvements):+.2f} points\")\n",
    "    print(f\"   Std improvement: Â±{np.std(all_improvements):.2f} points\")\n",
    "    print(f\"   Positive improvements: {sum(1 for x in all_improvements if x > 0)}/{len(all_improvements)} ({100*sum(1 for x in all_improvements if x > 0)/len(all_improvements):.1f}%)\")\n",
    "\n",
    "# Intersectional comparison\n",
    "if intersectional_results:\n",
    "    for demographics, results in intersectional_results.items():\n",
    "        metrics = results['overall_metrics']\n",
    "        print(f\"\\n4. INTERSECTIONAL INTERVENTION ({demographics})\")\n",
    "        print(f\"   Improvement: {metrics['improvement_mean']:+.1f} points\")\n",
    "        print(f\"   {metrics['baseline_accuracy_mean']*100:.1f}% (baseline) â†’ {metrics['intervention_accuracy_mean']*100:.1f}% (intervention)\")\n",
    "        \n",
    "        # Compare to best single demographic\n",
    "        if best_demo['Mean Improvement'] > metrics['improvement_mean']:\n",
    "            print(f\"   Note: Single demographic '{best_demo['Demographic']}' performed better (+{best_demo['Mean Improvement']:.2f} vs +{metrics['improvement_mean']:.2f})\")\n",
    "        else:\n",
    "            print(f\"   Note: Intersectional outperformed all single demographics!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results\n",
    "\n",
    "Optionally export analysis results to CSV for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to export\n",
    "# summary_df.to_csv(f'analysis_summary_{RUN_ID}.csv', index=False)\n",
    "# ranking_df.to_csv(f'demographic_rankings_{RUN_ID}.csv', index=False)\n",
    "# print(f\"Exported results to CSV files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
