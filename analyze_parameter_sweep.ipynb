{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Sweep Analysis\n",
    "\n",
    "This notebook analyzes intervention results across different parameter configurations to identify the optimal setup.\n",
    "\n",
    "**Parameters varied:**\n",
    "- `top_k_heads`: [5, 10, 20]\n",
    "- `intervention_strength`: [2.0, 5.0, 10.0, 100.0]\n",
    "\n",
    "**Total configurations:** 3 Ã— 4 = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Modify these to match your experiment\n",
    "# ============================================================================\n",
    "\n",
    "RUN_ID = \"20251120_120007\"  # Your experiment run ID\n",
    "PROBE_TYPE = \"attention\"  # attention, mlp, or both\n",
    "RESULTS_DIR = Path(\"robust_experiment_results/intervention_results\")\n",
    "\n",
    "# Parameter grid (should match your bash script)\n",
    "TOP_K_LIST = [5, 10, 20]\n",
    "INTERVENTION_STRENGTHS = [2.0, 5.0, 10.0, 100.0]\n",
    "DEMOGRAPHICS = ['gender', 'race', 'ideology']  # Order matters!\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Run ID: {RUN_ID}\")\n",
    "print(f\"  Probe Type: {PROBE_TYPE}\")\n",
    "print(f\"  Results Directory: {RESULTS_DIR}\")\n",
    "print(f\"  Top-K values: {TOP_K_LIST}\")\n",
    "print(f\"  Intervention strengths: {INTERVENTION_STRENGTHS}\")\n",
    "print(f\"  Demographics: {DEMOGRAPHICS}\")\n",
    "print(f\"  Total configurations: {len(TOP_K_LIST) * len(INTERVENTION_STRENGTHS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all result files\n",
    "all_results = []\n",
    "missing_files = []\n",
    "\n",
    "for demographic in DEMOGRAPHICS:\n",
    "    for top_k, strength in product(TOP_K_LIST, INTERVENTION_STRENGTHS):\n",
    "        # Construct filename with k and s parameters\n",
    "        filename = f\"{demographic}_{PROBE_TYPE}_k{top_k}_s{strength}_{RUN_ID}_intervention_results.pkl\"\n",
    "        filepath = RESULTS_DIR / filename\n",
    "        \n",
    "        if filepath.exists():\n",
    "            with open(filepath, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            \n",
    "            # Extract overall metrics\n",
    "            metrics = data['overall_metrics']\n",
    "            \n",
    "            result = {\n",
    "                'demographic': demographic,\n",
    "                'top_k': top_k,\n",
    "                'strength': strength,\n",
    "                'baseline_acc_mean': metrics['baseline_accuracy_mean'],\n",
    "                'baseline_acc_std': metrics.get('baseline_accuracy_std'),\n",
    "                'intervention_acc_mean': metrics['intervention_accuracy_mean'],\n",
    "                'intervention_acc_std': metrics.get('intervention_accuracy_std'),\n",
    "                'improvement_mean': metrics['improvement_mean'],\n",
    "                'improvement_std': metrics.get('improvement_std'),\n",
    "                'kendall_tau_baseline': metrics.get('baseline_kendall_tau_mean'),\n",
    "                'kendall_tau_intervention': metrics.get('intervention_kendall_tau_mean'),\n",
    "                'kendall_improvement': metrics.get('kendall_improvement_mean'),\n",
    "                'macro_f1_baseline': metrics.get('baseline_macro_f1_mean'),\n",
    "                'macro_f1_intervention': metrics.get('intervention_macro_f1_mean'),\n",
    "                'macro_f1_improvement': metrics.get('macro_f1_improvement_mean'),\n",
    "                'cohen_kappa_intervention': metrics.get('intervention_cohen_kappa_mean'),\n",
    "                'n_folds': data.get('n_folds', 3)\n",
    "            }\n",
    "            all_results.append(result)\n",
    "        else:\n",
    "            missing_files.append(filename)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"DATA LOADING SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Successfully loaded: {len(all_results)} configurations\")\n",
    "print(f\"Missing files: {len(missing_files)}\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\nMissing configurations:\")\n",
    "    for f in missing_files[:5]:  # Show first 5\n",
    "        print(f\"  - {f}\")\n",
    "    if len(missing_files) > 5:\n",
    "        print(f\"  ... and {len(missing_files) - 5} more\")\n",
    "\n",
    "print(f\"\\nLoaded data shape: {df.shape}\")\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Overall Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean improvement across all demographics for each configuration\n",
    "config_performance = df.groupby(['top_k', 'strength']).agg({\n",
    "    'improvement_mean': ['mean', 'std', 'count'],\n",
    "    'intervention_acc_mean': 'mean',\n",
    "    'baseline_acc_mean': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "config_performance.columns = ['top_k', 'strength', 'improvement_mean', 'improvement_std', \n",
    "                              'n_demographics', 'intervention_acc', 'baseline_acc']\n",
    "\n",
    "# Sort by improvement\n",
    "config_performance = config_performance.sort_values('improvement_mean', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 5 CONFIGURATIONS (by mean improvement across demographics)\")\n",
    "print(\"=\"*80)\n",
    "display(config_performance.head())\n",
    "\n",
    "# Announce winner\n",
    "best = config_performance.iloc[0]\n",
    "print(f\"\\nðŸ† BEST OVERALL CONFIGURATION:\")\n",
    "print(f\"   top_k_heads = {int(best['top_k'])}\")\n",
    "print(f\"   intervention_strength = {best['strength']}\")\n",
    "print(f\"   Mean improvement: {best['improvement_mean']:+.2f} points\")\n",
    "print(f\"   Std across demographics: Â±{best['improvement_std']:.2f}\")\n",
    "print(f\"   Baseline accuracy: {best['baseline_acc']*100:.1f}%\")\n",
    "print(f\"   Intervention accuracy: {best['intervention_acc']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Heatmap Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmaps for each demographic\n",
    "fig, axes = plt.subplots(1, len(DEMOGRAPHICS), figsize=(18, 5))\n",
    "\n",
    "for idx, demographic in enumerate(DEMOGRAPHICS):\n",
    "    ax = axes[idx] if len(DEMOGRAPHICS) > 1 else axes\n",
    "    \n",
    "    # Filter data for this demographic\n",
    "    demo_df = df[df['demographic'] == demographic]\n",
    "    \n",
    "    # Create pivot table: top_k (rows) Ã— strength (columns)\n",
    "    heatmap_data = demo_df.pivot(index='top_k', columns='strength', values='improvement_mean')\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt='.2f', cmap='RdYlGn', center=0,\n",
    "                ax=ax, cbar_kws={'label': 'Improvement (points)'},\n",
    "                vmin=-5, vmax=5)  # Adjust range as needed\n",
    "    \n",
    "    ax.set_title(f'{demographic.capitalize()} Intervention', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Intervention Strength', fontsize=10)\n",
    "    ax.set_ylabel('Top-K Heads', fontsize=10)\n",
    "    ax.invert_yaxis()  # Higher k at top\n",
    "\n",
    "plt.suptitle('Accuracy Improvement by Configuration and Demographic', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best configuration for each demographic\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST CONFIGURATION PER DEMOGRAPHIC\")\n",
    "print(\"=\"*80)\n",
    "for demographic in DEMOGRAPHICS:\n",
    "    demo_df = df[df['demographic'] == demographic]\n",
    "    best_idx = demo_df['improvement_mean'].idxmax()\n",
    "    best_row = demo_df.loc[best_idx]\n",
    "    print(f\"\\n{demographic.capitalize()}:\")\n",
    "    print(f\"  top_k = {int(best_row['top_k'])}, strength = {best_row['strength']}\")\n",
    "    print(f\"  Improvement: {best_row['improvement_mean']:+.2f} Â± {best_row['improvement_std']:.2f} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parameter Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Effect of top_k (separate lines for each strength)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left plot: Improvement vs top_k\n",
    "for strength in INTERVENTION_STRENGTHS:\n",
    "    data = df.groupby(['top_k', 'strength'])['improvement_mean'].mean().reset_index()\n",
    "    strength_data = data[data['strength'] == strength]\n",
    "    ax1.plot(strength_data['top_k'], strength_data['improvement_mean'], \n",
    "             marker='o', label=f'strength={strength}', linewidth=2)\n",
    "\n",
    "ax1.axhline(y=0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax1.set_xlabel('Top-K Heads', fontsize=11)\n",
    "ax1.set_ylabel('Mean Improvement (points)', fontsize=11)\n",
    "ax1.set_title('Effect of Top-K on Improvement', fontsize=12, fontweight='bold')\n",
    "ax1.legend(title='Intervention Strength')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Right plot: Improvement vs strength\n",
    "for top_k in TOP_K_LIST:\n",
    "    data = df.groupby(['top_k', 'strength'])['improvement_mean'].mean().reset_index()\n",
    "    topk_data = data[data['top_k'] == top_k]\n",
    "    ax2.plot(topk_data['strength'], topk_data['improvement_mean'], \n",
    "             marker='o', label=f'top_k={top_k}', linewidth=2)\n",
    "\n",
    "ax2.axhline(y=0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax2.set_xlabel('Intervention Strength', fontsize=11)\n",
    "ax2.set_ylabel('Mean Improvement (points)', fontsize=11)\n",
    "ax2.set_title('Effect of Strength on Improvement', fontsize=12, fontweight='bold')\n",
    "ax2.set_xscale('log')  # Log scale for strength\n",
    "ax2.legend(title='Top-K Heads')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PARAMETER SENSITIVITY SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Effect of top_k (averaged over all strengths)\n",
    "topk_effect = df.groupby('top_k')['improvement_mean'].agg(['mean', 'std'])\n",
    "print(\"\\nEffect of Top-K (averaged across all strengths):\")\n",
    "display(topk_effect)\n",
    "\n",
    "# Effect of strength (averaged over all top_k)\n",
    "strength_effect = df.groupby('strength')['improvement_mean'].agg(['mean', 'std'])\n",
    "print(\"\\nEffect of Strength (averaged across all top_k):\")\n",
    "display(strength_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare top 3 configurations across multiple metrics\n",
    "top_configs = config_performance.head(3)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "metrics = [\n",
    "    ('improvement_mean', 'Accuracy Improvement (points)'),\n",
    "    ('kendall_improvement', \"Kendall's Tau Improvement\"),\n",
    "    ('macro_f1_improvement', 'Macro F1 Improvement'),\n",
    "    ('cohen_kappa_intervention', \"Cohen's Kappa (Intervention)\")\n",
    "]\n",
    "\n",
    "for idx, (metric, label) in enumerate(metrics):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Get data for top 3 configs across all demographics\n",
    "    plot_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, config in top_configs.iterrows():\n",
    "        config_data = df[(df['top_k'] == config['top_k']) & \n",
    "                        (df['strength'] == config['strength'])]\n",
    "        \n",
    "        values = config_data[metric].dropna()\n",
    "        if len(values) > 0:\n",
    "            plot_data.append(values.tolist())\n",
    "            labels.append(f\"k={int(config['top_k'])}, s={config['strength']}\")\n",
    "    \n",
    "    if plot_data:\n",
    "        bp = ax.boxplot(plot_data, labels=labels, patch_artist=True)\n",
    "        for patch in bp['boxes']:\n",
    "            patch.set_facecolor('lightblue')\n",
    "        \n",
    "        ax.set_ylabel(label, fontsize=10)\n",
    "        ax.set_xlabel('Configuration', fontsize=10)\n",
    "        ax.set_title(f'Top 3 Configs: {label}', fontsize=11, fontweight='bold')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Rotate x labels\n",
    "        ax.tick_params(axis='x', rotation=15)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f'No data for {label}', \n",
    "                ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "plt.suptitle('Multi-Metric Comparison of Top 3 Configurations', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Robustness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze variance across folds (robustness)\n",
    "# Lower std = more robust/consistent results\n",
    "\n",
    "# Calculate mean improvement vs std for each configuration\n",
    "config_robustness = df.groupby(['top_k', 'strength']).agg({\n",
    "    'improvement_mean': 'mean',\n",
    "    'improvement_std': 'mean'  # Average std across demographics\n",
    "}).reset_index()\n",
    "\n",
    "# Scatter plot: improvement vs robustness\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "scatter = ax.scatter(config_robustness['improvement_mean'], \n",
    "                     config_robustness['improvement_std'],\n",
    "                     s=200, alpha=0.6, c=config_robustness['top_k'], \n",
    "                     cmap='viridis', edgecolors='black', linewidth=1.5)\n",
    "\n",
    "# Annotate each point\n",
    "for _, row in config_robustness.iterrows():\n",
    "    ax.annotate(f\"k={int(row['top_k'])}\\ns={row['strength']}\", \n",
    "                (row['improvement_mean'], row['improvement_std']),\n",
    "                fontsize=8, ha='center', va='center')\n",
    "\n",
    "ax.axvline(x=0, color='red', linestyle='--', linewidth=1, alpha=0.5, label='Zero improvement')\n",
    "ax.set_xlabel('Mean Improvement (points)', fontsize=11)\n",
    "ax.set_ylabel('Mean Std Dev (across folds)', fontsize=11)\n",
    "ax.set_title('Performance vs Robustness Trade-off', fontsize=13, fontweight='bold')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Top-K Heads', fontsize=10)\n",
    "\n",
    "# Ideal region (high improvement, low std)\n",
    "ax.axhspan(0, config_robustness['improvement_std'].quantile(0.25), \n",
    "           alpha=0.1, color='green', label='Low variance region')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find most robust configurations\n",
    "robust_configs = config_robustness.nsmallest(5, 'improvement_std')\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MOST ROBUST CONFIGURATIONS (lowest variance across folds)\")\n",
    "print(\"=\"*80)\n",
    "display(robust_configs)\n",
    "\n",
    "# Best trade-off: high improvement AND low std\n",
    "# Normalize both metrics to [0, 1] and find best combined score\n",
    "config_robustness['norm_improvement'] = (\n",
    "    (config_robustness['improvement_mean'] - config_robustness['improvement_mean'].min()) /\n",
    "    (config_robustness['improvement_mean'].max() - config_robustness['improvement_mean'].min())\n",
    ")\n",
    "config_robustness['norm_std'] = (\n",
    "    (config_robustness['improvement_std'] - config_robustness['improvement_std'].min()) /\n",
    "    (config_robustness['improvement_std'].max() - config_robustness['improvement_std'].min())\n",
    ")\n",
    "config_robustness['combined_score'] = config_robustness['norm_improvement'] - config_robustness['norm_std']\n",
    "\n",
    "best_tradeoff = config_robustness.nlargest(3, 'combined_score')\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST PERFORMANCE-ROBUSTNESS TRADE-OFF\")\n",
    "print(\"=\"*80)\n",
    "display(best_tradeoff[['top_k', 'strength', 'improvement_mean', 'improvement_std', 'combined_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Overall best\n",
    "best = config_performance.iloc[0]\n",
    "print(f\"\\n1. BEST OVERALL CONFIGURATION:\")\n",
    "print(f\"   â†’ top_k_heads = {int(best['top_k'])}\")\n",
    "print(f\"   â†’ intervention_strength = {best['strength']}\")\n",
    "print(f\"   â†’ Expected improvement: {best['improvement_mean']:+.2f} Â± {best['improvement_std']:.2f} points\")\n",
    "\n",
    "# 2. Most robust\n",
    "most_robust = robust_configs.iloc[0]\n",
    "print(f\"\\n2. MOST ROBUST CONFIGURATION (lowest variance):\")\n",
    "print(f\"   â†’ top_k_heads = {int(most_robust['top_k'])}\")\n",
    "print(f\"   â†’ intervention_strength = {most_robust['strength']}\")\n",
    "print(f\"   â†’ Improvement: {most_robust['improvement_mean']:+.2f} Â± {most_robust['improvement_std']:.2f} points\")\n",
    "\n",
    "# 3. Best trade-off\n",
    "tradeoff = best_tradeoff.iloc[0]\n",
    "print(f\"\\n3. BEST PERFORMANCE-ROBUSTNESS TRADE-OFF:\")\n",
    "print(f\"   â†’ top_k_heads = {int(tradeoff['top_k'])}\")\n",
    "print(f\"   â†’ intervention_strength = {tradeoff['strength']}\")\n",
    "print(f\"   â†’ Improvement: {tradeoff['improvement_mean']:+.2f} Â± {tradeoff['improvement_std']:.2f} points\")\n",
    "\n",
    "# 4. Per-demographic recommendations\n",
    "print(f\"\\n4. PER-DEMOGRAPHIC RECOMMENDATIONS:\")\n",
    "for demographic in DEMOGRAPHICS:\n",
    "    demo_df = df[df['demographic'] == demographic]\n",
    "    best_idx = demo_df['improvement_mean'].idxmax()\n",
    "    best_row = demo_df.loc[best_idx]\n",
    "    print(f\"   {demographic.capitalize()}: k={int(best_row['top_k'])}, s={best_row['strength']} \"\n",
    "          f\"({best_row['improvement_mean']:+.2f} points)\")\n",
    "\n",
    "# 5. Suggested next experiments\n",
    "print(f\"\\n5. SUGGESTED NEXT EXPERIMENTS:\")\n",
    "\n",
    "# Check if best is at boundary\n",
    "best_k = int(best['top_k'])\n",
    "best_s = best['strength']\n",
    "\n",
    "if best_k == min(TOP_K_LIST):\n",
    "    print(f\"   - Try lower top_k values (e.g., 3, 4) - best was at minimum tested\")\n",
    "elif best_k == max(TOP_K_LIST):\n",
    "    print(f\"   - Try higher top_k values (e.g., 30, 50) - best was at maximum tested\")\n",
    "else:\n",
    "    print(f\"   - top_k seems optimal around {best_k}\")\n",
    "\n",
    "if best_s == min(INTERVENTION_STRENGTHS):\n",
    "    print(f\"   - Try lower strength values (e.g., 0.5, 1.0) - best was at minimum tested\")\n",
    "elif best_s == max(INTERVENTION_STRENGTHS):\n",
    "    print(f\"   - Try higher strength values (e.g., 200, 500) - best was at maximum tested\")\n",
    "else:\n",
    "    print(f\"   - strength seems optimal around {best_s}\")\n",
    "\n",
    "print(f\"   - Fine-tune around best config: k âˆˆ [{max(5, best_k-2)}, {best_k+2}], \"\n",
    "      f\"s âˆˆ [{best_s*0.5}, {best_s*2}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export best configuration to JSON for easy reuse\n",
    "best_config = {\n",
    "    'top_k_heads': int(best['top_k']),\n",
    "    'intervention_strength': float(best['strength']),\n",
    "    'expected_improvement': float(best['improvement_mean']),\n",
    "    'improvement_std': float(best['improvement_std']),\n",
    "    'intervention_accuracy': float(best['intervention_acc']),\n",
    "    'baseline_accuracy': float(best['baseline_acc']),\n",
    "    'run_id': RUN_ID,\n",
    "    'probe_type': PROBE_TYPE,\n",
    "    'demographics': DEMOGRAPHICS\n",
    "}\n",
    "\n",
    "# Uncomment to save\n",
    "# import json\n",
    "# with open(f'best_config_{RUN_ID}.json', 'w') as f:\n",
    "#     json.dump(best_config, f, indent=2)\n",
    "# print(f\"Best configuration saved to best_config_{RUN_ID}.json\")\n",
    "\n",
    "print(\"\\nBest Configuration:\")\n",
    "print(json.dumps(best_config, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
